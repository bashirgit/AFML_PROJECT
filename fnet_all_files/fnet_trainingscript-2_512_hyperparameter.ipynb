{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18a335e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: biopython in /home/mluser/.venv/lib/python3.12/site-packages (1.85)\n",
      "Requirement already satisfied: transformers in /home/mluser/.venv/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: torch in /home/mluser/.venv/lib/python3.12/site-packages (2.9.0)\n",
      "Requirement already satisfied: datasets in /home/mluser/.venv/lib/python3.12/site-packages (4.2.0)\n",
      "Requirement already satisfied: numpy in /home/mluser/.venv/lib/python3.12/site-packages (2.3.4)\n",
      "Requirement already satisfied: scikit-learn in /home/mluser/.venv/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: evaluate in /home/mluser/.venv/lib/python3.12/site-packages (0.4.6)\n",
      "Requirement already satisfied: filelock in /home/mluser/.venv/lib/python3.12/site-packages (from transformers) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers) (0.35.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in /home/mluser/.venv/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mluser/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mluser/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/mluser/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: setuptools in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /home/mluser/.venv/lib/python3.12/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /home/mluser/.venv/lib/python3.12/site-packages (from datasets) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /home/mluser/.venv/lib/python3.12/site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in /home/mluser/.venv/lib/python3.12/site-packages (from datasets) (2.3.3)\n",
      "Requirement already satisfied: httpx<1.0.0 in /home/mluser/.venv/lib/python3.12/site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /home/mluser/.venv/lib/python3.12/site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /home/mluser/.venv/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/mluser/.venv/lib/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.0)\n",
      "Requirement already satisfied: anyio in /home/mluser/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
      "Requirement already satisfied: certifi in /home/mluser/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /home/mluser/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in /home/mluser/.venv/lib/python3.12/site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /home/mluser/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /home/mluser/.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/mluser/.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/mluser/.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /home/mluser/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /home/mluser/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/mluser/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/mluser/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/mluser/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /home/mluser/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /home/mluser/.venv/lib/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mluser/.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mluser/.venv/lib/python3.12/site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mluser/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/mluser/.venv/lib/python3.12/site-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mluser/.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mluser/.venv/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/mluser/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/mluser/.venv/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/mluser/.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install biopython transformers torch datasets numpy scikit-learn evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6020c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /home/mluser/.venv/lib/python3.12/site-packages (4.57.1)\n",
      "Requirement already satisfied: filelock in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (3.20.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (0.35.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (2025.9.18)\n",
      "Requirement already satisfied: requests in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch>=2.2 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (2.9.0)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/mluser/.venv/lib/python3.12/site-packages (from transformers[torch]) (1.10.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/mluser/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (2025.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/mluser/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/mluser/.venv/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers[torch]) (1.1.10)\n",
      "Requirement already satisfied: psutil in /home/mluser/.venv/lib/python3.12/site-packages (from accelerate>=0.26.0->transformers[torch]) (7.1.0)\n",
      "Requirement already satisfied: setuptools in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /home/mluser/.venv/lib/python3.12/site-packages (from torch>=2.2->transformers[torch]) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/mluser/.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.2->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mluser/.venv/lib/python3.12/site-packages (from jinja2->torch>=2.2->transformers[torch]) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/mluser/.venv/lib/python3.12/site-packages (from requests->transformers[torch]) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/mluser/.venv/lib/python3.12/site-packages (from requests->transformers[torch]) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/mluser/.venv/lib/python3.12/site-packages (from requests->transformers[torch]) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mluser/.venv/lib/python3.12/site-packages (from requests->transformers[torch]) (2025.10.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59246fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForMaskedLM,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "import numpy as np\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "import evaluate\n",
    "import inspect\n",
    "\n",
    "print(\"‚úÖ Imports complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e895d205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ GPU cache cleared\n",
      "   GPU: NVIDIA GeForce RTX 4090\n",
      "   Total GPU memory: 25.25 GB\n",
      "   Available memory: 25.25 GB\n"
     ]
    }
   ],
   "source": [
    "# Clear GPU cache before starting\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(f\"‚úÖ GPU cache cleared\")\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Total GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(f\"   Available memory: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated(0)) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca836fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tokenizer loaded\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"google/fnet-base\")\n",
    "print(\"‚úÖ Tokenizer loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3750af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FASTADataset class defined\n"
     ]
    }
   ],
   "source": [
    "class FASTADataset(Dataset):\n",
    "    def __init__(self, fasta_file, tokenizer, max_length=512):\n",
    "        print(f\"Loading sequences from {fasta_file}...\")\n",
    "        self.sequences = []\n",
    "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "            seq = str(record.seq)\n",
    "            if len(seq) > 0:\n",
    "                self.sequences.append(seq)\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        print(f\"Loaded {len(self.sequences)} sequences\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = self.sequences[idx]\n",
    "        spaced_seq = \" \".join(list(seq))\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            spaced_seq,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        result = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "        \n",
    "        if 'attention_mask' not in result:\n",
    "            result['attention_mask'] = torch.ones_like(result['input_ids'])\n",
    "        \n",
    "        return result\n",
    "\n",
    "print(\"‚úÖ FASTADataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2735ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Found: /home/mluser/AFML_RISHABH/Project/10k sequences/kinases_cluster_train_10k.fasta\n",
      "‚úì Found: /home/mluser/AFML_RISHABH/Project/10k sequences/kinases_cluster_val_10k.fasta\n",
      "‚úì Found: /home/mluser/AFML_RISHABH/Project/10k sequences/kinases_cluster_test_10k.fasta\n",
      "Loading sequences from /home/mluser/AFML_RISHABH/Project/10k sequences/kinases_cluster_train_10k.fasta...\n",
      "Loaded 7989 sequences\n",
      "Loading sequences from /home/mluser/AFML_RISHABH/Project/10k sequences/kinases_cluster_val_10k.fasta...\n",
      "Loaded 1002 sequences\n",
      "Loading sequences from /home/mluser/AFML_RISHABH/Project/10k sequences/kinases_cluster_test_10k.fasta...\n",
      "Loaded 1009 sequences\n",
      "\n",
      "==================================================\n",
      "Dataset sizes: 7989, 1002, 1009\n",
      "Max sequence length: 512\n",
      "==================================================\n",
      "\n",
      "Testing dataset[0]...\n",
      "‚úì Sample retrieved successfully\n",
      "  Keys: dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "  input_ids shape: torch.Size([512])\n",
      "  First 20 tokens: [4, 94, 123, 100, 153, 266, 101, 66, 129, 66, 66, 66, 66, 66, 66, 66, 101, 70, 101, 66]\n"
     ]
    }
   ],
   "source": [
    "data_folder = '/home/mluser/AFML_RISHABH/Project/10k sequences'\n",
    "\n",
    "train_path = os.path.join(data_folder, \"kinases_cluster_train_10k.fasta\")\n",
    "val_path   = os.path.join(data_folder, \"kinases_cluster_val_10k.fasta\")\n",
    "test_path  = os.path.join(data_folder, \"kinases_cluster_test_10k.fasta\")\n",
    "\n",
    "# Verify files exist\n",
    "for path in [train_path, val_path, test_path]:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"File not found: {path}\")\n",
    "    print(f\"‚úì Found: {path}\")\n",
    "\n",
    "# Use reduced max_length to save memory\n",
    "MAX_LENGTH = 512  # Reduced from 512\n",
    "\n",
    "train_dataset = FASTADataset(train_path, tokenizer, max_length=MAX_LENGTH)\n",
    "val_dataset   = FASTADataset(val_path, tokenizer, max_length=MAX_LENGTH)\n",
    "test_dataset  = FASTADataset(test_path, tokenizer, max_length=MAX_LENGTH)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"Dataset sizes: {len(train_dataset)}, {len(val_dataset)}, {len(test_dataset)}\")\n",
    "print(f\"Max sequence length: {MAX_LENGTH}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Test dataset\n",
    "print(\"\\nTesting dataset[0]...\")\n",
    "sample = train_dataset[0]\n",
    "print(\"‚úì Sample retrieved successfully\")\n",
    "print(f\"  Keys: {sample.keys()}\")\n",
    "print(f\"  input_ids shape: {sample['input_ids'].shape}\")\n",
    "print(f\"  First 20 tokens: {sample['input_ids'][:20].tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e4fa0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Gradient checkpointing enabled\n",
      "‚úÖ Model ready on cuda\n",
      "   GPU memory allocated: 0.33 GB\n",
      "   GPU memory reserved: 0.37 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mluser/.venv/lib/python3.12/site-packages/torch/__init__.py:1617: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at /pytorch/aten/src/ATen/Context.cpp:80.)\n",
      "  _C._set_float32_matmul_precision(precision)\n"
     ]
    }
   ],
   "source": [
    "from transformers.models.fnet.modeling_fnet import FNetBasicFourierTransform\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"google/fnet-base\")\n",
    "\n",
    "# Patch FNet Fourier Transform for float32\n",
    "class FNetSafeFourierTransform(FNetBasicFourierTransform):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self, hidden_states):\n",
    "        hidden_states = hidden_states.to(torch.float32)\n",
    "        outputs = torch.fft.fftn(hidden_states, dim=(-2, -1)).real\n",
    "        return (outputs,)\n",
    "\n",
    "model.fourier_transform = FNetSafeFourierTransform(model.config)\n",
    "\n",
    "# Force FP32 and handle unexpected kwargs\n",
    "def force_fp32_forward(original_forward):\n",
    "    sig = inspect.signature(original_forward)\n",
    "    \n",
    "    def wrapped_forward(*args, **kwargs):\n",
    "        valid_params = set(sig.parameters.keys())\n",
    "        filtered_kwargs = {k: v for k, v in kwargs.items() if k in valid_params}\n",
    "        \n",
    "        with torch.autocast(device_type='cuda', enabled=False):\n",
    "            return original_forward(*args, **filtered_kwargs)\n",
    "    \n",
    "    return wrapped_forward\n",
    "\n",
    "model.forward = force_fp32_forward(model.forward)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device).to(torch.float32)\n",
    "torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "# Enable gradient checkpointing to save memory\n",
    "if hasattr(model, 'gradient_checkpointing_enable'):\n",
    "    model.gradient_checkpointing_enable()\n",
    "    print(\"‚úì Gradient checkpointing enabled\")\n",
    "\n",
    "print(f\"‚úÖ Model ready on {device}\")\n",
    "\n",
    "# Check memory usage\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU memory allocated: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "    print(f\"   GPU memory reserved: {torch.cuda.memory_reserved(0) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2700607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data collator...\n",
      "‚úì Collated batch keys: KeysView({'input_ids': tensor([[  4,  94,   6,  ...,   6, 101,   5],\n",
      "        [  4,  94, 123,  ..., 101, 164,   5]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
      "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]]), 'labels': tensor([[-100, -100,  123,  ...,  101, -100, -100],\n",
      "        [-100, -100, -100,  ..., -100, -100, -100]])})\n",
      "  input_ids shape: torch.Size([2, 512])\n",
      "  labels shape: torch.Size([2, 512])\n"
     ]
    }
   ],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15\n",
    ")\n",
    "\n",
    "# Test the data collator\n",
    "print(\"Testing data collator...\")\n",
    "batch = [train_dataset[i] for i in range(2)]\n",
    "collated = data_collator(batch)\n",
    "print(f\"‚úì Collated batch keys: {collated.keys()}\")\n",
    "print(f\"  input_ids shape: {collated['input_ids'].shape}\")\n",
    "print(f\"  labels shape: {collated['labels'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a97ac80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total combinations to run: 24\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# === Hyperparameter Ranges ===\n",
    "learning_rates = [3e-5, 5e-5, 7e-5]\n",
    "weight_decays = [0.01, 0.05]\n",
    "batch_sizes = [1, 2]\n",
    "gradient_accumulation_steps_list = [4, 8]\n",
    "max_seq_lengths = [512]  # Fixed for this experiment\n",
    "num_train_epochs = 10\n",
    "\n",
    "# === Generate all combinations ===\n",
    "hyperparameter_combinations = list(product(\n",
    "    learning_rates,\n",
    "    weight_decays,\n",
    "    batch_sizes,\n",
    "    gradient_accumulation_steps_list,\n",
    "    max_seq_lengths\n",
    "))\n",
    "print(f\"Total combinations to run: {len(hyperparameter_combinations)}\")\n",
    "\n",
    "# === TrainingArguments factory ===\n",
    "def get_training_args(run_id, learning_rate, weight_decay, batch_size, grad_accum, max_seq_len, output_dir=None):\n",
    "    if output_dir is None:\n",
    "        output_dir = f\"./KinaseFNet_10k_hparam_run_{run_id}\"\n",
    "\n",
    "    return TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        overwrite_output_dir=True,\n",
    "        num_train_epochs=num_train_epochs,\n",
    "        per_device_train_batch_size=batch_size,\n",
    "        gradient_accumulation_steps=grad_accum,\n",
    "        save_strategy=\"epoch\",\n",
    "        save_total_limit=num_train_epochs,\n",
    "        logging_steps=100,\n",
    "        learning_rate=learning_rate,\n",
    "        weight_decay=weight_decay,\n",
    "        fp16=False,\n",
    "        bf16=False,\n",
    "        eval_strategy=\"no\",\n",
    "        dataloader_num_workers=0,\n",
    "        remove_unused_columns=False,\n",
    "        gradient_checkpointing=True,\n",
    "        optim=\"adamw_torch\",\n",
    "        max_grad_norm=1.0,\n",
    "        logging_first_step=True,\n",
    "        report_to=\"none\",\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "490beb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metrics configured\n"
     ]
    }
   ],
   "source": [
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    mask = labels != -100\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    preds = preds[mask]\n",
    "    labels = labels[mask]\n",
    "    return accuracy_metric.compute(predictions=preds, references=labels)\n",
    "\n",
    "print(\"‚úÖ Metrics configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c1ff99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Cleared GPU cache\n",
      "‚úÖ Trainer created successfully (no evaluation during training)\n",
      "\n",
      "Testing trainer dataloader...\n",
      "‚úì Dataloader test passed\n",
      "  Batch input_ids shape: torch.Size([1, 512])\n",
      "  GPU memory: 0.33 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3008/1914814.py:29: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from contextlib import nullcontext\n",
    "import torch\n",
    "\n",
    "# Clear any stale accelerator state\n",
    "try:\n",
    "    from accelerate.state import AcceleratorState\n",
    "    if hasattr(AcceleratorState, '_shared_state') and AcceleratorState._shared_state:\n",
    "        AcceleratorState._reset_state()\n",
    "        print(\"‚úì Cleared accelerator state\")\n",
    "except Exception as e:\n",
    "    print(f\"Note: Could not clear accelerator state: {e}\")\n",
    "\n",
    "# Clear GPU cache\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"‚úì Cleared GPU cache\")\n",
    "\n",
    "# ‚úÖ Create TrainingArguments instance from your function (fixed argument names)\n",
    "training_args = get_training_args(\n",
    "    run_id=0,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    batch_size=1,\n",
    "    grad_accum=8,\n",
    "    max_seq_len=512\n",
    ")\n",
    "\n",
    "# ‚úÖ Create trainer WITHOUT eval_dataset to avoid evaluation during training\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Disable autocast for stability\n",
    "trainer.autocast_smart_context_manager = nullcontext\n",
    "\n",
    "print(\"‚úÖ Trainer created successfully (no evaluation during training)\")\n",
    "\n",
    "# Quick dataloader test\n",
    "print(\"\\nTesting trainer dataloader...\")\n",
    "try:\n",
    "    train_dataloader = trainer.get_train_dataloader()\n",
    "    test_batch = next(iter(train_dataloader))\n",
    "    print(f\"‚úì Dataloader test passed\")\n",
    "    print(f\"  Batch input_ids shape: {test_batch['input_ids'].shape}\")\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"  GPU memory: {torch.cuda.memory_allocated(0) / 1e9:.2f} GB\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Dataloader test failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "18b5f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45457e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Loaded 22 completed runs from hyperparam_runs/summary.csv\n",
      "‚è≠Ô∏è Skipping Run 1: already done (lr=3e-05, wd=0.01, bs=1, grad_acc=4, len=512)\n",
      "‚è≠Ô∏è Skipping Run 2: already done (lr=3e-05, wd=0.01, bs=1, grad_acc=8, len=512)\n",
      "‚è≠Ô∏è Skipping Run 3: already done (lr=3e-05, wd=0.01, bs=2, grad_acc=4, len=512)\n",
      "‚è≠Ô∏è Skipping Run 4: already done (lr=3e-05, wd=0.01, bs=2, grad_acc=8, len=512)\n",
      "‚è≠Ô∏è Skipping Run 5: already done (lr=3e-05, wd=0.05, bs=1, grad_acc=4, len=512)\n",
      "‚è≠Ô∏è Skipping Run 6: already done (lr=3e-05, wd=0.05, bs=1, grad_acc=8, len=512)\n",
      "‚è≠Ô∏è Skipping Run 7: already done (lr=3e-05, wd=0.05, bs=2, grad_acc=4, len=512)\n",
      "‚è≠Ô∏è Skipping Run 8: already done (lr=3e-05, wd=0.05, bs=2, grad_acc=8, len=512)\n",
      "‚è≠Ô∏è Skipping Run 9: already done (lr=5e-05, wd=0.01, bs=1, grad_acc=4, len=512)\n",
      "‚è≠Ô∏è Skipping Run 10: already done (lr=5e-05, wd=0.01, bs=1, grad_acc=8, len=512)\n",
      "‚è≠Ô∏è Skipping Run 11: already done (lr=5e-05, wd=0.01, bs=2, grad_acc=4, len=512)\n",
      "‚è≠Ô∏è Skipping Run 12: already done (lr=5e-05, wd=0.01, bs=2, grad_acc=8, len=512)\n",
      "‚è≠Ô∏è Skipping Run 13: already done (lr=5e-05, wd=0.05, bs=1, grad_acc=4, len=512)\n",
      "‚è≠Ô∏è Skipping Run 14: already done (lr=5e-05, wd=0.05, bs=1, grad_acc=8, len=512)\n",
      "\n",
      "====================================================================================================\n",
      "üèÅ Starting Run 15/24 ‚Üí run_015_lr5e-05_wd0.05_bs2_ga4_len512\n",
      "====================================================================================================\n",
      "‚úì Cleared GPU cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_566/1945148403.py:65: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9990' max='9990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9990/9990 17:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.199900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.511800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.589800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>8.463200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.450300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.453700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.400300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>8.438000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>8.368200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>8.369800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.320700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>8.243000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>8.360300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>8.238500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>8.276700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>8.265400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>8.289100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>8.226700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>8.144600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>8.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>8.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>8.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>8.060800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>8.004600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>8.074000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>8.018400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>8.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>8.049800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>8.050800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>8.063700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>7.889300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>7.835500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>7.865100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>7.944100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>8.056200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>7.850500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>7.849700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>7.813800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>7.964700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>7.961100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>7.892100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>7.761100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>7.788200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>7.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>7.945900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>7.844400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>7.798000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>7.870700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>7.850400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>7.785300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>7.799100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>7.766600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>7.712300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>7.738800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>7.705300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>7.821600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>7.748900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>7.886000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>7.882400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>7.890500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>7.856100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>7.842400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>7.760300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>7.732800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>7.709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>7.713800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>7.701500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>7.828800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>7.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>7.772600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>7.766100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>7.823100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>7.719000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>7.808800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>7.701600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>7.706000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>7.758900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>7.763900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>7.763900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>7.824100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>7.736900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>7.817400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>7.716900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>7.882400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>7.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>7.684600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>7.757900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>7.864800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>7.786300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>7.639800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>7.763800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>7.709500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>7.762100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>7.854500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>7.826200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>7.767400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>7.906200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>7.753200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>7.763700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>7.747200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Run 15 completed successfully!\n",
      "üíæ Model + tokenizer saved to hyperparam_runs/run_015_lr5e-05_wd0.05_bs2_ga4_len512\n",
      "üìä Saved log_history.csv for run 15\n",
      "üìÅ Saved master summary to hyperparam_runs/summary.csv\n",
      "üßπ CUDA memory cleared.\n",
      "\n",
      "‚è≠Ô∏è Skipping Run 16: already done (lr=5e-05, wd=0.05, bs=2, grad_acc=8, len=512)\n",
      "‚è≠Ô∏è Skipping Run 17: already done (lr=7e-05, wd=0.01, bs=1, grad_acc=4, len=512)\n",
      "‚è≠Ô∏è Skipping Run 18: already done (lr=7e-05, wd=0.01, bs=1, grad_acc=8, len=512)\n",
      "\n",
      "====================================================================================================\n",
      "üèÅ Starting Run 19/24 ‚Üí run_019_lr7e-05_wd0.01_bs2_ga4_len512\n",
      "====================================================================================================\n",
      "‚úì Cleared accelerator state\n",
      "‚úì Cleared GPU cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_566/1945148403.py:65: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9990' max='9990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9990/9990 17:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>7.686600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>7.407200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>7.586700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>7.407600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>7.424300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.477600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>7.419700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>7.479500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>7.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>7.417900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.402700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>7.272400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>7.422700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>7.314500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>7.385300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>7.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>7.401400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>7.363000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>7.255500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>7.396500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>7.327000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>7.342400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>7.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>7.129300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>7.222600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>7.177800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>7.275500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>7.265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>7.258900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>7.265800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>7.082000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>7.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>7.078100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>7.164900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>7.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>7.065200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>7.097400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>7.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>7.240300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>7.248700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>7.162900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>7.012900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>7.054400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>7.210900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>7.281900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>7.156800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>7.101000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>7.190200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>7.185800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>7.112400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>7.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>7.070200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>7.035200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>7.090100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>7.042500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>7.210800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>7.131800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>7.301000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>7.280800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>7.289800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>7.289200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>7.251900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>7.188600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>7.149800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>7.107400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>7.156700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>7.136600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>7.297400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>7.216200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>7.237700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>7.246200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>7.308900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>7.187900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>7.288300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>7.187700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>7.195600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>7.251800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>7.265400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>7.269100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>7.351000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>7.264400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>7.337300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>7.242900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>7.429300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>7.297700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>7.231200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>7.319200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>7.440900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>7.355300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>7.201100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>7.338700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>7.263300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>7.338200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>7.447400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>7.422900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>7.369400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>7.519200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>7.357700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>7.403200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>7.386600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Run 19 completed successfully!\n",
      "üíæ Model + tokenizer saved to hyperparam_runs/run_019_lr7e-05_wd0.01_bs2_ga4_len512\n",
      "üìä Saved log_history.csv for run 19\n",
      "üìÅ Saved master summary to hyperparam_runs/summary.csv\n",
      "üßπ CUDA memory cleared.\n",
      "\n",
      "‚è≠Ô∏è Skipping Run 20: already done (lr=7e-05, wd=0.01, bs=2, grad_acc=8, len=512)\n",
      "‚è≠Ô∏è Skipping Run 21: already done (lr=7e-05, wd=0.05, bs=1, grad_acc=4, len=512)\n",
      "‚è≠Ô∏è Skipping Run 22: already done (lr=7e-05, wd=0.05, bs=1, grad_acc=8, len=512)\n",
      "‚è≠Ô∏è Skipping Run 23: already done (lr=7e-05, wd=0.05, bs=2, grad_acc=4, len=512)\n",
      "‚è≠Ô∏è Skipping Run 24: already done (lr=7e-05, wd=0.05, bs=2, grad_acc=8, len=512)\n",
      "\n",
      "‚úÖ All hyperparameter runs completed!\n",
      "üì¶ Master summary available at: hyperparam_runs/summary.csv\n"
     ]
    }
   ],
   "source": [
    "import torch, gc, pandas as pd, os\n",
    "from contextlib import nullcontext\n",
    "from accelerate.state import AcceleratorState\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "BASE_DIR = \"hyperparam_runs\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "MASTER_CSV = os.path.join(BASE_DIR, \"summary.csv\")\n",
    "\n",
    "results = []\n",
    "completed = set()\n",
    "\n",
    "# --- Load completed runs if CSV exists ---\n",
    "if os.path.exists(MASTER_CSV):\n",
    "    prev_df = pd.read_csv(MASTER_CSV)\n",
    "    for _, row in prev_df.iterrows():\n",
    "        combo = (row[\"learning_rate\"], row[\"weight_decay\"], row[\"batch_size\"], row[\"grad_accum\"], row[\"max_seq_len\"])\n",
    "        completed.add(combo)\n",
    "    results = prev_df.to_dict(orient=\"records\")\n",
    "    print(f\"üîÅ Loaded {len(completed)} completed runs from {MASTER_CSV}\")\n",
    "else:\n",
    "    print(\"üÜï Starting fresh ‚Äî no previous runs found.\")\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "for i, (lr, wd, bs, grad_acc, max_len) in enumerate(hyperparameter_combinations, 1):\n",
    "    combo = (lr, wd, bs, grad_acc, max_len)\n",
    "    if combo in completed:\n",
    "        print(f\"‚è≠Ô∏è Skipping Run {i}: already done (lr={lr}, wd={wd}, bs={bs}, grad_acc={grad_acc}, len={max_len})\")\n",
    "        continue\n",
    "\n",
    "    # Create a unique folder for this run\n",
    "    run_name = f\"run_{i:03d}_lr{lr}_wd{wd}_bs{bs}_ga{grad_acc}_len{max_len}\"\n",
    "    run_dir = os.path.join(BASE_DIR, run_name)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"üèÅ Starting Run {i}/{len(hyperparameter_combinations)} ‚Üí {run_name}\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    # --- Reset accelerator cleanly ---\n",
    "    try:\n",
    "        if hasattr(AcceleratorState, \"_shared_state\") and AcceleratorState._shared_state:\n",
    "            AcceleratorState._reset_state()\n",
    "            print(\"‚úì Cleared accelerator state\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not clear accelerator state: {e}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(\"‚úì Cleared GPU cache\")\n",
    "\n",
    "    # --- Create TrainingArguments for this run ---\n",
    "    training_args = get_training_args(\n",
    "        run_id=i,\n",
    "        learning_rate=lr,\n",
    "        weight_decay=wd,\n",
    "        batch_size=bs,\n",
    "        grad_accum=grad_acc,\n",
    "        max_seq_len=max_len,\n",
    "        output_dir=run_dir  # <--- store checkpoints in this folder\n",
    "    )\n",
    "\n",
    "    # --- Create Trainer ---\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    trainer.autocast_smart_context_manager = nullcontext\n",
    "\n",
    "    # --- Train and Save ---\n",
    "    try:\n",
    "        train_result = trainer.train()\n",
    "        status = \"Success\"\n",
    "        print(f\"‚úÖ Run {i} completed successfully!\")\n",
    "\n",
    "        # Save model + tokenizer + run logs\n",
    "        trainer.save_model(run_dir)\n",
    "        tokenizer.save_pretrained(run_dir)\n",
    "        torch.save(training_args, os.path.join(run_dir, \"training_args.pt\"))\n",
    "        print(f\"üíæ Model + tokenizer saved to {run_dir}\")\n",
    "\n",
    "        # Save training log history\n",
    "        if hasattr(trainer.state, \"log_history\"):\n",
    "            pd.DataFrame(trainer.state.log_history).to_csv(os.path.join(run_dir, \"log_history.csv\"), index=False)\n",
    "            print(f\"üìä Saved log_history.csv for run {i}\")\n",
    "    except RuntimeError as e:\n",
    "        status = \"OOM\" if \"out of memory\" in str(e).lower() else \"Failed\"\n",
    "        print(f\"‚ùå Run {i} failed: {status}\")\n",
    "    except Exception as e:\n",
    "        status = f\"Error: {str(e)[:80]}\"\n",
    "        print(f\"‚ùå Run {i} crashed with error: {e}\")\n",
    "    finally:\n",
    "        # Record the run summary\n",
    "        results.append({\n",
    "            \"run_id\": i,\n",
    "            \"learning_rate\": lr,\n",
    "            \"weight_decay\": wd,\n",
    "            \"batch_size\": bs,\n",
    "            \"grad_accum\": grad_acc,\n",
    "            \"max_seq_len\": max_len,\n",
    "            \"output_dir\": run_dir,\n",
    "            \"status\": status,\n",
    "        })\n",
    "        completed.add(combo)\n",
    "\n",
    "        # Save master summary CSV\n",
    "        pd.DataFrame(results).to_csv(MASTER_CSV, index=False)\n",
    "        print(f\"üìÅ Saved master summary to {MASTER_CSV}\")\n",
    "\n",
    "        # Clear GPU memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        print(\"üßπ CUDA memory cleared.\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ All hyperparameter runs completed!\")\n",
    "print(f\"üì¶ Master summary available at: {MASTER_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31aa043",
   "metadata": {},
   "source": [
    "Evaluation of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414bdaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, DataCollatorForLanguageModeling\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import inspect\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5aafc544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in full dataset: 10,000\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_001_lr3e-05_wd0.01_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_001_lr3e-05_wd0.01_bs1_ga4_len512 ‚Äî Loss: 2.1171, Perplexity: 8.31\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_002_lr3e-05_wd0.01_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_002_lr3e-05_wd0.01_bs1_ga8_len512 ‚Äî Loss: 2.0297, Perplexity: 7.61\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_003_lr3e-05_wd0.01_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_003_lr3e-05_wd0.01_bs2_ga4_len512 ‚Äî Loss: 1.9467, Perplexity: 7.01\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_004_lr3e-05_wd0.01_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_004_lr3e-05_wd0.01_bs2_ga8_len512 ‚Äî Loss: 1.9030, Perplexity: 6.71\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_005_lr3e-05_wd0.05_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_005_lr3e-05_wd0.05_bs1_ga4_len512 ‚Äî Loss: 2.1256, Perplexity: 8.38\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_006_lr3e-05_wd0.05_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_006_lr3e-05_wd0.05_bs1_ga8_len512 ‚Äî Loss: 2.1753, Perplexity: 8.80\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_007_lr3e-05_wd0.05_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_007_lr3e-05_wd0.05_bs2_ga4_len512 ‚Äî Loss: 2.0450, Perplexity: 7.73\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_008_lr3e-05_wd0.05_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_008_lr3e-05_wd0.05_bs2_ga8_len512 ‚Äî Loss: 2.0371, Perplexity: 7.67\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_009_lr5e-05_wd0.01_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_009_lr5e-05_wd0.01_bs1_ga4_len512 ‚Äî Loss: 2.0508, Perplexity: 7.77\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_010_lr5e-05_wd0.01_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_010_lr5e-05_wd0.01_bs1_ga8_len512 ‚Äî Loss: 1.9365, Perplexity: 6.93\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_011_lr5e-05_wd0.01_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_011_lr5e-05_wd0.01_bs2_ga4_len512 ‚Äî Loss: 1.8384, Perplexity: 6.29\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_012_lr5e-05_wd0.01_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_012_lr5e-05_wd0.01_bs2_ga8_len512 ‚Äî Loss: 1.7880, Perplexity: 5.98\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_013_lr5e-05_wd0.05_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_013_lr5e-05_wd0.05_bs1_ga4_len512 ‚Äî Loss: 1.7333, Perplexity: 5.66\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_014_lr5e-05_wd0.05_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_014_lr5e-05_wd0.05_bs1_ga8_len512 ‚Äî Loss: 1.7086, Perplexity: 5.52\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_015_lr5e-05_wd0.05_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_015_lr5e-05_wd0.05_bs2_ga4_len512 ‚Äî Loss: 1.9603, Perplexity: 7.10\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_016_lr5e-05_wd0.05_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_016_lr5e-05_wd0.05_bs2_ga8_len512 ‚Äî Loss: 2.1463, Perplexity: 8.55\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_017_lr7e-05_wd0.01_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_017_lr7e-05_wd0.01_bs1_ga4_len512 ‚Äî Loss: 1.9241, Perplexity: 6.85\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_018_lr7e-05_wd0.01_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_018_lr7e-05_wd0.01_bs1_ga8_len512 ‚Äî Loss: 1.8282, Perplexity: 6.22\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_019_lr7e-05_wd0.01_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_019_lr7e-05_wd0.01_bs2_ga4_len512 ‚Äî Loss: 1.8712, Perplexity: 6.50\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_020_lr7e-05_wd0.01_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_020_lr7e-05_wd0.01_bs2_ga8_len512 ‚Äî Loss: 1.9280, Perplexity: 6.88\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_021_lr7e-05_wd0.05_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_021_lr7e-05_wd0.05_bs1_ga4_len512 ‚Äî Loss: 1.8121, Perplexity: 6.12\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_022_lr7e-05_wd0.05_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_022_lr7e-05_wd0.05_bs1_ga8_len512 ‚Äî Loss: 1.7461, Perplexity: 5.73\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_023_lr7e-05_wd0.05_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_023_lr7e-05_wd0.05_bs2_ga4_len512 ‚Äî Loss: 1.6756, Perplexity: 5.34\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_024_lr7e-05_wd0.05_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                     "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_024_lr7e-05_wd0.05_bs2_ga8_len512 ‚Äî Loss: 2.0971, Perplexity: 8.14\n",
      "\n",
      "============================================================\n",
      "All Evaluations Complete ‚úÖ\n",
      "Results saved to: /home/mluser/AFML_RISHABH/Project/hyperparam_runs/evaluation_results.csv\n",
      "============================================================\n",
      "                                model_run  avg_loss  perplexity\n",
      "0   run_001_lr3e-05_wd0.01_bs1_ga4_len512  2.117117    8.307150\n",
      "1   run_002_lr3e-05_wd0.01_bs1_ga8_len512  2.029656    7.611469\n",
      "2   run_003_lr3e-05_wd0.01_bs2_ga4_len512  1.946687    7.005442\n",
      "3   run_004_lr3e-05_wd0.01_bs2_ga8_len512  1.902977    6.705826\n",
      "4   run_005_lr3e-05_wd0.05_bs1_ga4_len512  2.125601    8.377933\n",
      "5   run_006_lr3e-05_wd0.05_bs1_ga8_len512  2.175255    8.804427\n",
      "6   run_007_lr3e-05_wd0.05_bs2_ga4_len512  2.045010    7.729234\n",
      "7   run_008_lr3e-05_wd0.05_bs2_ga8_len512  2.037138    7.668630\n",
      "8   run_009_lr5e-05_wd0.01_bs1_ga4_len512  2.050794    7.774068\n",
      "9   run_010_lr5e-05_wd0.01_bs1_ga8_len512  1.936474    6.934260\n",
      "10  run_011_lr5e-05_wd0.01_bs2_ga4_len512  1.838383    6.286367\n",
      "11  run_012_lr5e-05_wd0.01_bs2_ga8_len512  1.788021    5.977610\n",
      "12  run_013_lr5e-05_wd0.05_bs1_ga4_len512  1.733344    5.659547\n",
      "13  run_014_lr5e-05_wd0.05_bs1_ga8_len512  1.708551    5.520954\n",
      "14  run_015_lr5e-05_wd0.05_bs2_ga4_len512  1.960306    7.101502\n",
      "15  run_016_lr5e-05_wd0.05_bs2_ga8_len512  2.146327    8.553383\n",
      "16  run_017_lr7e-05_wd0.01_bs1_ga4_len512  1.924098    6.848966\n",
      "17  run_018_lr7e-05_wd0.01_bs1_ga8_len512  1.828191    6.222621\n",
      "18  run_019_lr7e-05_wd0.01_bs2_ga4_len512  1.871198    6.496071\n",
      "19  run_020_lr7e-05_wd0.01_bs2_ga8_len512  1.928038    6.876007\n",
      "20  run_021_lr7e-05_wd0.05_bs1_ga4_len512  1.812149    6.123593\n",
      "21  run_022_lr7e-05_wd0.05_bs1_ga8_len512  1.746100    5.732206\n",
      "22  run_023_lr7e-05_wd0.05_bs2_ga4_len512  1.675629    5.342153\n",
      "23  run_024_lr7e-05_wd0.05_bs2_ga8_len512  2.097136    8.142817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SETUP\n",
    "# ============================================================\n",
    "base_dir = \"/home/mluser/AFML_RISHABH/Project/hyperparam_runs\"\n",
    "results = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# PATCH FUNCTION\n",
    "# ============================================================\n",
    "def safe_forward(original_forward):\n",
    "    sig = inspect.signature(original_forward)\n",
    "    valid_keys = set(sig.parameters.keys())\n",
    "    def wrapped_forward(*args, **kwargs):\n",
    "        filtered = {k: v for k, v in kwargs.items() if k in valid_keys}\n",
    "        return original_forward(*args, **filtered)\n",
    "    return wrapped_forward\n",
    "\n",
    "# ============================================================\n",
    "# MERGE DATASETS (Assuming train_dataset, val_dataset, test_dataset exist)\n",
    "# ============================================================\n",
    "full_dataset = ConcatDataset([train_dataset, val_dataset, test_dataset])\n",
    "print(f\"Total samples in full dataset: {len(full_dataset):,}\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LOOP OVER ALL RUNS\n",
    "# ============================================================\n",
    "for run_name in sorted(os.listdir(base_dir)):\n",
    "    run_path = os.path.join(base_dir, run_name)\n",
    "    if not os.path.isdir(run_path):\n",
    "        continue\n",
    "    print(\"\\n============================================================\")\n",
    "    print(f\"Evaluating model: {run_name}\")\n",
    "    print(\"============================================================\")\n",
    "\n",
    "    try:\n",
    "        # Load model and tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(run_path)\n",
    "        model = AutoModelForMaskedLM.from_pretrained(run_path)\n",
    "        model.forward = safe_forward(model.forward)\n",
    "        model = model.to(device).eval()\n",
    "\n",
    "        # Set tokenizer in collator\n",
    "        data_collator.tokenizer = tokenizer\n",
    "\n",
    "        # DataLoader\n",
    "        test_loader = DataLoader(full_dataset, batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=f\"Evaluating {run_name}\", leave=False):\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "                if loss is not None:\n",
    "                    total_loss += loss.item() * batch[\"input_ids\"].size(0)\n",
    "                    total_count += batch[\"input_ids\"].size(0)\n",
    "\n",
    "        if total_count > 0:\n",
    "            avg_loss = total_loss / total_count\n",
    "            perplexity = math.exp(avg_loss)\n",
    "            print(f\"‚úÖ {run_name} ‚Äî Loss: {avg_loss:.4f}, Perplexity: {perplexity:.2f}\")\n",
    "        else:\n",
    "            avg_loss, perplexity = None, None\n",
    "            print(f\"‚ö†Ô∏è {run_name} ‚Äî No valid batches.\")\n",
    "\n",
    "        results.append({\n",
    "            \"model_run\": run_name,\n",
    "            \"avg_loss\": avg_loss,\n",
    "            \"perplexity\": perplexity\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error evaluating {run_name}: {e}\")\n",
    "        results.append({\n",
    "            \"model_run\": run_name,\n",
    "            \"avg_loss\": None,\n",
    "            \"perplexity\": None\n",
    "        })\n",
    "\n",
    "# ============================================================\n",
    "# SAVE RESULTS\n",
    "# ============================================================\n",
    "df = pd.DataFrame(results)\n",
    "output_csv = os.path.join(base_dir, \"evaluation_results.csv\")\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"\\n============================================================\")\n",
    "print(\"All Evaluations Complete ‚úÖ\")\n",
    "print(f\"Results saved to: {output_csv}\")\n",
    "print(\"============================================================\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbb92b9",
   "metadata": {},
   "source": [
    "## 4 more hyperparamters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e66e7e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3008/1307176744.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'eos_token_id': None, 'bos_token_id': None}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÅ Loaded 24 completed runs from /home/mluser/AFML_RISHABH/Project/hyperparam_runs/summary.csv\n",
      "\n",
      "====================================================================================================\n",
      "üèÅ Starting Run 1/4 ‚Üí run_next_001_lr8e-05_wd0.05_bs2_ga4_len512\n",
      "====================================================================================================\n",
      "‚úì Cleared accelerator state\n",
      "‚úì Cleared GPU cache\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9990' max='9990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9990/9990 16:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.542400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>10.499900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>10.375500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>10.272100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>10.134400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>10.006500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>9.894200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>9.866000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>9.754400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>9.681000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>9.572000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>9.498000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>9.515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>9.428200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>9.405500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>9.377700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>9.347500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>9.255300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>9.242200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>9.271300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>9.190300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>9.186400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>9.098100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>9.038700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>9.062600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>8.993300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>9.049200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>8.994000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>8.968300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>8.997200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>8.848600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>8.804500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>8.799200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>8.834400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>8.900200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>8.743100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>8.729300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>8.728500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>8.779700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>8.758500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>8.695900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>8.595200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>8.598800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>8.659500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>8.672700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>8.617300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>8.555100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>8.594800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>8.568900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>8.533900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>8.515300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>8.496400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>8.417300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>8.428500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>8.415000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>8.468000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>8.396600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>8.493500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>8.487600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>8.481600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>8.448000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>8.418000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>8.380200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>8.316100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>8.301200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>8.273700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>8.262000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>8.345100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>8.297600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>8.286000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>8.266900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>8.286900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>8.223800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>8.278800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>8.172300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>8.162100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>8.208600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>8.219700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>8.197700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>8.227400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>8.146600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>8.203900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>8.125900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>8.248000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>8.126200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>8.070400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>8.103700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>8.198300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>8.142900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>7.983900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>8.104100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>8.046600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>8.066300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>8.134400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>8.120900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>8.039900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>8.169300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>8.023700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>8.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>7.991700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Run 1 completed successfully!\n",
      "üíæ Model + tokenizer saved to /home/mluser/AFML_RISHABH/Project/hyperparam_runs/run_next_001_lr8e-05_wd0.05_bs2_ga4_len512\n",
      "üìä Saved log_history.csv for run 1\n",
      "üìÅ Saved master summary to /home/mluser/AFML_RISHABH/Project/hyperparam_runs/summary.csv\n",
      "üßπ CUDA memory cleared.\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "üèÅ Starting Run 2/4 ‚Üí run_next_002_lr7e-05_wd0.03_bs2_ga4_len512\n",
      "====================================================================================================\n",
      "‚úì Cleared accelerator state\n",
      "‚úì Cleared GPU cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3008/1307176744.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9990' max='9990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9990/9990 16:48, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.025900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>8.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.350800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>8.186300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>8.193800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>8.181600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>8.132800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>8.184900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>8.111500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>8.092400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>8.063900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>7.954600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>8.074200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>7.988700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>8.001700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>7.975400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>8.015300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>7.929000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>7.845400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>7.950800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>7.863700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>7.895700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>7.756600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>7.712800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>7.758100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>7.692000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>7.764400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>7.740500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>7.719900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>7.738800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>7.583100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>7.506100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>7.515500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>7.591400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>7.728300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>7.485000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>7.506600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>7.453300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>7.628400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>7.623500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>7.549100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>7.394000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>7.425400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>7.559700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>7.595100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>7.495100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>7.435200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>7.496600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>7.472400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>7.415700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>7.415700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>7.367100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>7.296700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>7.368900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>7.328300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>7.486000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>7.374100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>7.522100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>7.510100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>7.500600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>7.497600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>7.452900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>7.415600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>7.341200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>7.305400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>7.341200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>7.330700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>7.475100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>7.372900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>7.390100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>7.388000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>7.451500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>7.342100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>7.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>7.333000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>7.323500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>7.395600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>7.410600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>7.386100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>7.453600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>7.397000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>7.449400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>7.382400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>7.510500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>7.392200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>7.342800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>7.403700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>7.517600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>7.459900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>7.293900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>7.424100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>7.351200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>7.408500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>7.519900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>7.500200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>7.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>7.580500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>7.421800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>7.451300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>7.446800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Run 2 completed successfully!\n",
      "üíæ Model + tokenizer saved to /home/mluser/AFML_RISHABH/Project/hyperparam_runs/run_next_002_lr7e-05_wd0.03_bs2_ga4_len512\n",
      "üìä Saved log_history.csv for run 2\n",
      "üìÅ Saved master summary to /home/mluser/AFML_RISHABH/Project/hyperparam_runs/summary.csv\n",
      "üßπ CUDA memory cleared.\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "üèÅ Starting Run 3/4 ‚Üí run_next_003_lr7e-05_wd0.05_bs4_ga2_len512\n",
      "====================================================================================================\n",
      "‚úì Cleared accelerator state\n",
      "‚úì Cleared GPU cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3008/1307176744.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9990' max='9990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [9990/9990 15:25, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>3.817300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>3.882400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>3.787300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>3.816900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.822600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.840300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.847300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.817000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.830900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.785200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.796900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.783100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.799700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.781100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.807900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>3.768300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>3.733200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>3.788600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.761300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>3.780300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>3.746200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>3.701600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>3.735100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>3.699300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>3.723000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>3.727500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>3.760100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>3.743000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.669900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>3.660700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>3.635000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>3.709600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>3.746300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>3.635700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>3.642700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>3.642600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>3.733500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>3.696200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.689200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>3.585700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>3.624800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>3.688600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>3.691400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>3.646000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>3.626200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>3.635400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>3.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>3.616500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.616000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>3.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>3.560900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>3.573800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>3.557900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>3.633400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>3.555900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>3.649500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>3.645000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>3.634500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.664400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>3.604500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>3.605200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>3.553900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>3.514000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>3.553700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>3.527800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6700</td>\n",
       "      <td>3.614400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>3.573300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6900</td>\n",
       "      <td>3.570900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.577100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7100</td>\n",
       "      <td>3.603200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>3.539700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7300</td>\n",
       "      <td>3.578400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>3.539100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>3.536200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>3.531900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7700</td>\n",
       "      <td>3.551800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>3.549700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7900</td>\n",
       "      <td>3.565600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.544700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8100</td>\n",
       "      <td>3.532500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>3.503600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8300</td>\n",
       "      <td>3.567400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>3.529400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>3.478900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>3.548700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8700</td>\n",
       "      <td>3.582100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>3.518100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8900</td>\n",
       "      <td>3.449400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.520700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9100</td>\n",
       "      <td>3.488800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>3.494400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9300</td>\n",
       "      <td>3.559300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>3.547000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>3.527400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>3.576800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9700</td>\n",
       "      <td>3.474400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>3.521400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9900</td>\n",
       "      <td>3.493500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Run 3 completed successfully!\n",
      "üíæ Model + tokenizer saved to /home/mluser/AFML_RISHABH/Project/hyperparam_runs/run_next_003_lr7e-05_wd0.05_bs4_ga2_len512\n",
      "üìä Saved log_history.csv for run 3\n",
      "üìÅ Saved master summary to /home/mluser/AFML_RISHABH/Project/hyperparam_runs/summary.csv\n",
      "üßπ CUDA memory cleared.\n",
      "\n",
      "\n",
      "====================================================================================================\n",
      "üèÅ Starting Run 4/4 ‚Üí run_next_004_lr7e-05_wd0.05_bs1_ga8_len768\n",
      "====================================================================================================\n",
      "‚úì Cleared accelerator state\n",
      "‚úì Cleared GPU cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3008/1307176744.py:80: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='593' max='9990' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 593/9990 01:11 < 19:02, 8.22 it/s, Epoch 0.59/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>15.017100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>14.217900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>14.415300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>14.032800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>14.231900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>14.277600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Saved master summary to /home/mluser/AFML_RISHABH/Project/hyperparam_runs/summary.csv\n",
      "üßπ CUDA memory cleared.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 91\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# --- Train and Save ---\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     train_result = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m     status = \u001b[33m\"\u001b[39m\u001b[33mSuccess\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     93\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Run \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m completed successfully!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/transformers/trainer.py:2325\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2323\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2324\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2325\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2326\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2327\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2328\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2329\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2330\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/transformers/trainer.py:2674\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2667\u001b[39m context = (\n\u001b[32m   2668\u001b[39m     functools.partial(\u001b[38;5;28mself\u001b[39m.accelerator.no_sync, model=model)\n\u001b[32m   2669\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i != \u001b[38;5;28mlen\u001b[39m(batch_samples) - \u001b[32m1\u001b[39m\n\u001b[32m   2670\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type != DistributedType.DEEPSPEED\n\u001b[32m   2671\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m contextlib.nullcontext\n\u001b[32m   2672\u001b[39m )\n\u001b[32m   2673\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m-> \u001b[39m\u001b[32m2674\u001b[39m     tr_loss_step = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   2677\u001b[39m     args.logging_nan_inf_filter\n\u001b[32m   2678\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[32m   2679\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (torch.isnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch.isinf(tr_loss_step))\n\u001b[32m   2680\u001b[39m ):\n\u001b[32m   2681\u001b[39m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[32m   2682\u001b[39m     tr_loss = tr_loss + tr_loss / (\u001b[32m1\u001b[39m + \u001b[38;5;28mself\u001b[39m.state.global_step - \u001b[38;5;28mself\u001b[39m._globalstep_last_logged)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/transformers/trainer.py:4071\u001b[39m, in \u001b[36mTrainer.training_step\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m   4068\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.accelerator.distributed_type == DistributedType.DEEPSPEED:\n\u001b[32m   4069\u001b[39m         kwargs[\u001b[33m\"\u001b[39m\u001b[33mscale_wrt_gas\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4071\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maccelerator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4073\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loss.detach()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/accelerate/accelerator.py:2734\u001b[39m, in \u001b[36mAccelerator.backward\u001b[39m\u001b[34m(self, loss, **kwargs)\u001b[39m\n\u001b[32m   2732\u001b[39m     \u001b[38;5;28mself\u001b[39m.lomo_backward(loss, learning_rate)\n\u001b[32m   2733\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2734\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch, gc, pandas as pd, os\n",
    "from contextlib import nullcontext\n",
    "from accelerate.state import AcceleratorState\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "BASE_DIR = \"/home/mluser/AFML_RISHABH/Project/hyperparam_runs\"\n",
    "os.makedirs(BASE_DIR, exist_ok=True)\n",
    "MASTER_CSV = os.path.join(BASE_DIR, \"summary.csv\")\n",
    "\n",
    "results = []\n",
    "completed = set()\n",
    "\n",
    "# --- Load completed runs if CSV exists ---\n",
    "if os.path.exists(MASTER_CSV):\n",
    "    prev_df = pd.read_csv(MASTER_CSV)\n",
    "    for _, row in prev_df.iterrows():\n",
    "        combo = (row[\"learning_rate\"], row[\"weight_decay\"], row[\"batch_size\"], row[\"grad_accum\"], row[\"max_seq_len\"])\n",
    "        completed.add(combo)\n",
    "    results = prev_df.to_dict(orient=\"records\")\n",
    "    print(f\"üîÅ Loaded {len(completed)} completed runs from {MASTER_CSV}\")\n",
    "else:\n",
    "    print(\"üÜï Starting fresh ‚Äî no previous runs found.\")\n",
    "\n",
    "# ========== NEW HYPERPARAMETER COMBINATIONS ==========\n",
    "hyperparameter_combinations = [\n",
    "    # Run A ‚Äî push LR slightly higher\n",
    "    (8e-5, 0.05, 2, 4, 512),\n",
    "\n",
    "    # Run B ‚Äî reduce regularization a bit\n",
    "    (7e-5, 0.03, 2, 4, 512),\n",
    "\n",
    "    # Run C ‚Äî change batch/grad_acc balance\n",
    "    (7e-5, 0.05, 4, 2, 512),\n",
    "\n",
    "    # Run D ‚Äî longer context window test\n",
    "    (7e-5, 0.05, 1, 8, 768),\n",
    "]\n",
    "\n",
    "# --- MAIN LOOP ---\n",
    "for i, (lr, wd, bs, grad_acc, max_len) in enumerate(hyperparameter_combinations, 1):\n",
    "    combo = (lr, wd, bs, grad_acc, max_len)\n",
    "    if combo in completed:\n",
    "        print(f\"‚è≠Ô∏è Skipping Run {i}: already done (lr={lr}, wd={wd}, bs={bs}, grad_acc={grad_acc}, len={max_len})\")\n",
    "        continue\n",
    "\n",
    "    # Create a unique folder for this run\n",
    "    run_name = f\"run_next_{i:03d}_lr{lr}_wd{wd}_bs{bs}_ga{grad_acc}_len{max_len}\"\n",
    "    run_dir = os.path.join(BASE_DIR, run_name)\n",
    "    os.makedirs(run_dir, exist_ok=True)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\"üèÅ Starting Run {i}/{len(hyperparameter_combinations)} ‚Üí {run_name}\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "    # --- Reset accelerator cleanly ---\n",
    "    try:\n",
    "        if hasattr(AcceleratorState, \"_shared_state\") and AcceleratorState._shared_state:\n",
    "            AcceleratorState._reset_state()\n",
    "            print(\"‚úì Cleared accelerator state\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Could not clear accelerator state: {e}\")\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        print(\"‚úì Cleared GPU cache\")\n",
    "\n",
    "    # --- Create TrainingArguments for this run ---\n",
    "    training_args = get_training_args(\n",
    "        run_id=i,\n",
    "        learning_rate=lr,\n",
    "        weight_decay=wd,\n",
    "        batch_size=bs,\n",
    "        grad_accum=grad_acc,\n",
    "        max_seq_len=max_len,\n",
    "        output_dir=run_dir  # <--- store checkpoints in this folder\n",
    "    )\n",
    "\n",
    "    # --- Create Trainer ---\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    trainer.autocast_smart_context_manager = nullcontext\n",
    "\n",
    "    # --- Train and Save ---\n",
    "    try:\n",
    "        train_result = trainer.train()\n",
    "        status = \"Success\"\n",
    "        print(f\"‚úÖ Run {i} completed successfully!\")\n",
    "\n",
    "        # Save model + tokenizer + run logs\n",
    "        trainer.save_model(run_dir)\n",
    "        tokenizer.save_pretrained(run_dir)\n",
    "        torch.save(training_args, os.path.join(run_dir, \"training_args.pt\"))\n",
    "        print(f\"üíæ Model + tokenizer saved to {run_dir}\")\n",
    "\n",
    "        # Save training log history\n",
    "        if hasattr(trainer.state, \"log_history\"):\n",
    "            pd.DataFrame(trainer.state.log_history).to_csv(os.path.join(run_dir, \"log_history.csv\"), index=False)\n",
    "            print(f\"üìä Saved log_history.csv for run {i}\")\n",
    "    except RuntimeError as e:\n",
    "        status = \"OOM\" if \"out of memory\" in str(e).lower() else \"Failed\"\n",
    "        print(f\"‚ùå Run {i} failed: {status}\")\n",
    "    except Exception as e:\n",
    "        status = f\"Error: {str(e)[:80]}\"\n",
    "        print(f\"‚ùå Run {i} crashed with error: {e}\")\n",
    "    finally:\n",
    "        # Record the run summary\n",
    "        results.append({\n",
    "            \"run_id\": i,\n",
    "            \"learning_rate\": lr,\n",
    "            \"weight_decay\": wd,\n",
    "            \"batch_size\": bs,\n",
    "            \"grad_accum\": grad_acc,\n",
    "            \"max_seq_len\": max_len,\n",
    "            \"output_dir\": run_dir,\n",
    "            \"status\": status,\n",
    "        })\n",
    "        completed.add(combo)\n",
    "\n",
    "        # Save master summary CSV\n",
    "        pd.DataFrame(results).to_csv(MASTER_CSV, index=False)\n",
    "        print(f\"üìÅ Saved master summary to {MASTER_CSV}\")\n",
    "\n",
    "        # Clear GPU memory\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            gc.collect()\n",
    "        print(\"üßπ CUDA memory cleared.\\n\")\n",
    "\n",
    "print(\"\\n‚úÖ All hyperparameter runs completed!\")\n",
    "print(f\"üì¶ Master summary available at: {MASTER_CSV}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297b8526",
   "metadata": {},
   "source": [
    "## Evaluation of the 3 HPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfce58f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in full dataset: 10,000\n",
      "üîÅ Loaded existing evaluation results (24 runs)\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_next_001_lr8e-05_wd0.05_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_next_001_lr8e-05_wd0.05_bs2_ga4_len512 ‚Äî Loss: 2.0265, Perplexity: 7.59\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_next_002_lr7e-05_wd0.03_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_next_002_lr7e-05_wd0.03_bs2_ga4_len512 ‚Äî Loss: 1.8955, Perplexity: 6.66\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_next_003_lr7e-05_wd0.05_bs4_ga2_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_next_003_lr7e-05_wd0.05_bs4_ga2_len512 ‚Äî Loss: 1.7844, Perplexity: 5.96\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_next_004_lr7e-05_wd0.05_bs1_ga8_len768\n",
      "============================================================\n",
      "‚ùå Error evaluating run_next_004_lr7e-05_wd0.05_bs1_ga8_len768: Unrecognized model in /home/mluser/AFML_RISHABH/Project/hyperparam_runs/run_next_004_lr7e-05_wd0.05_bs1_ga8_len768. Should have a `model_type` key in its config.json, or contain one of the following strings in its name: aimv2, aimv2_vision_model, albert, align, altclip, apertus, arcee, aria, aria_text, audio-spectrogram-transformer, autoformer, aya_vision, bamba, bark, bart, beit, bert, bert-generation, big_bird, bigbird_pegasus, biogpt, bit, bitnet, blenderbot, blenderbot-small, blip, blip-2, blip_2_qformer, bloom, blt, bridgetower, bros, camembert, canine, chameleon, chinese_clip, chinese_clip_vision_model, clap, clip, clip_text_model, clip_vision_model, clipseg, clvp, code_llama, codegen, cohere, cohere2, cohere2_vision, colpali, colqwen2, conditional_detr, convbert, convnext, convnextv2, cpmant, csm, ctrl, cvt, d_fine, dab-detr, dac, data2vec-audio, data2vec-text, data2vec-vision, dbrx, deberta, deberta-v2, decision_transformer, deepseek_v2, deepseek_v3, deepseek_vl, deepseek_vl_hybrid, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dia, diffllama, dinat, dinov2, dinov2_with_registers, dinov3_convnext, dinov3_vit, distilbert, doge, donut-swin, dots1, dpr, dpt, edgetam, edgetam_video, edgetam_vision_model, efficientformer, efficientloftr, efficientnet, electra, emu3, encodec, encoder-decoder, eomt, ernie, ernie4_5, ernie4_5_moe, ernie_m, esm, evolla, exaone4, falcon, falcon_h1, falcon_mamba, fastspeech2_conformer, fastspeech2_conformer_with_hifigan, flaubert, flava, flex_olmo, florence2, fnet, focalnet, fsmt, funnel, fuyu, gemma, gemma2, gemma3, gemma3_text, gemma3n, gemma3n_audio, gemma3n_text, gemma3n_vision, git, glm, glm4, glm4_moe, glm4v, glm4v_moe, glm4v_moe_text, glm4v_text, glpn, got_ocr2, gpt-sw3, gpt2, gpt_bigcode, gpt_neo, gpt_neox, gpt_neox_japanese, gpt_oss, gptj, gptsan-japanese, granite, granite_speech, granitemoe, granitemoehybrid, granitemoeshared, granitevision, graphormer, grounding-dino, groupvit, helium, hgnet_v2, hiera, hubert, hunyuan_v1_dense, hunyuan_v1_moe, ibert, idefics, idefics2, idefics3, idefics3_vision, ijepa, imagegpt, informer, instructblip, instructblipvideo, internvl, internvl_vision, jamba, janus, jetmoe, jukebox, kosmos-2, kosmos-2.5, kyutai_speech_to_text, layoutlm, layoutlmv2, layoutlmv3, led, levit, lfm2, lfm2_vl, lightglue, lilt, llama, llama4, llama4_text, llava, llava_next, llava_next_video, llava_onevision, longcat_flash, longformer, longt5, luke, lxmert, m2m_100, mamba, mamba2, marian, markuplm, mask2former, maskformer, maskformer-swin, mbart, mctct, mega, megatron-bert, metaclip_2, mgp-str, mimi, minimax, ministral, mistral, mistral3, mixtral, mlcd, mllama, mm-grounding-dino, mobilebert, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, modernbert, modernbert-decoder, moonshine, moshi, mpnet, mpt, mra, mt5, musicgen, musicgen_melody, mvp, nat, nemotron, nezha, nllb-moe, nougat, nystromformer, olmo, olmo2, olmo3, olmoe, omdet-turbo, oneformer, open-llama, openai-gpt, opt, ovis2, owlv2, owlvit, paligemma, parakeet_ctc, parakeet_encoder, patchtsmixer, patchtst, pegasus, pegasus_x, perceiver, perception_encoder, perception_lm, persimmon, phi, phi3, phi4_multimodal, phimoe, pix2struct, pixtral, plbart, poolformer, pop2piano, prompt_depth_anything, prophetnet, pvt, pvt_v2, qdqbert, qwen2, qwen2_5_omni, qwen2_5_vl, qwen2_5_vl_text, qwen2_audio, qwen2_audio_encoder, qwen2_moe, qwen2_vl, qwen2_vl_text, qwen3, qwen3_moe, qwen3_next, qwen3_omni_moe, qwen3_vl, qwen3_vl_moe, qwen3_vl_moe_text, qwen3_vl_text, rag, realm, recurrent_gemma, reformer, regnet, rembert, resnet, retribert, roberta, roberta-prelayernorm, roc_bert, roformer, rt_detr, rt_detr_resnet, rt_detr_v2, rwkv, sam, sam2, sam2_hiera_det_model, sam2_video, sam2_vision_model, sam_hq, sam_hq_vision_model, sam_vision_model, seamless_m4t, seamless_m4t_v2, seed_oss, segformer, seggpt, sew, sew-d, shieldgemma2, siglip, siglip2, siglip2_vision_model, siglip_vision_model, smollm3, smolvlm, smolvlm_vision, speech-encoder-decoder, speech_to_text, speech_to_text_2, speecht5, splinter, squeezebert, stablelm, starcoder2, superglue, superpoint, swiftformer, swin, swin2sr, swinv2, switch_transformers, t5, t5gemma, table-transformer, tapas, textnet, time_series_transformer, timesfm, timesformer, timm_backbone, timm_wrapper, trajectory_transformer, transfo-xl, trocr, tvlt, tvp, udop, umt5, unispeech, unispeech-sat, univnet, upernet, van, vaultgemma, video_llava, videomae, vilt, vipllava, vision-encoder-decoder, vision-text-dual-encoder, visual_bert, vit, vit_hybrid, vit_mae, vit_msn, vitdet, vitmatte, vitpose, vitpose_backbone, vits, vivit, vjepa2, voxtral, voxtral_encoder, wav2vec2, wav2vec2-bert, wav2vec2-conformer, wavlm, whisper, xclip, xcodec, xglm, xlm, xlm-prophetnet, xlm-roberta, xlm-roberta-xl, xlnet, xlstm, xmod, yolos, yoso, zamba, zamba2, zoedepth\n",
      "\n",
      "============================================================\n",
      "‚úÖ Evaluation Complete for New Runs\n",
      "============================================================\n",
      "                                    model_run  avg_loss  perplexity\n",
      "0  run_next_001_lr8e-05_wd0.05_bs2_ga4_len512  2.026539    7.587777\n",
      "1  run_next_002_lr7e-05_wd0.03_bs2_ga4_len512  1.895524    6.656036\n",
      "2  run_next_003_lr7e-05_wd0.05_bs4_ga2_len512  1.784413    5.956082\n",
      "3  run_next_004_lr7e-05_wd0.05_bs1_ga8_len768       NaN         NaN\n",
      "\n",
      "üìÅ Results saved to: /home/mluser/AFML_RISHABH/Project/hyperparam_runs/evaluation_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import torch, os, math, pandas as pd, inspect\n",
    "from torch.utils.data import ConcatDataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================================================\n",
    "# SETUP\n",
    "# ============================================================\n",
    "base_dir = \"/home/mluser/AFML_RISHABH/Project/hyperparam_runs\"\n",
    "results = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# PATCH FUNCTION\n",
    "# ============================================================\n",
    "def safe_forward(original_forward):\n",
    "    sig = inspect.signature(original_forward)\n",
    "    valid_keys = set(sig.parameters.keys())\n",
    "    def wrapped_forward(*args, **kwargs):\n",
    "        filtered = {k: v for k, v in kwargs.items() if k in valid_keys}\n",
    "        return original_forward(*args, **filtered)\n",
    "    return wrapped_forward\n",
    "\n",
    "# ============================================================\n",
    "# MERGE DATASETS (Assuming train_dataset, val_dataset, test_dataset exist)\n",
    "# ============================================================\n",
    "full_dataset = ConcatDataset([train_dataset, val_dataset, test_dataset])\n",
    "print(f\"Total samples in full dataset: {len(full_dataset):,}\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD EXISTING CSV (if exists)\n",
    "# ============================================================\n",
    "output_csv = os.path.join(base_dir, \"evaluation_results.csv\")\n",
    "if os.path.exists(output_csv):\n",
    "    existing_df = pd.read_csv(output_csv)\n",
    "    existing_runs = set(existing_df[\"model_run\"])\n",
    "    print(f\"üîÅ Loaded existing evaluation results ({len(existing_df)} runs)\")\n",
    "else:\n",
    "    existing_df = pd.DataFrame(columns=[\"model_run\", \"avg_loss\", \"perplexity\"])\n",
    "    existing_runs = set()\n",
    "    print(\"üÜï No previous evaluation file found ‚Äî starting fresh.\")\n",
    "\n",
    "# ============================================================\n",
    "# LOOP OVER NEW RUNS (only run_next_ folders)\n",
    "# ============================================================\n",
    "new_results = []\n",
    "\n",
    "for run_name in sorted(os.listdir(base_dir)):\n",
    "    run_path = os.path.join(base_dir, run_name)\n",
    "    if not os.path.isdir(run_path):\n",
    "        continue\n",
    "    if not run_name.startswith(\"run_next_\"):\n",
    "        continue\n",
    "    if run_name in existing_runs:\n",
    "        print(f\"‚è≠Ô∏è Skipping {run_name} ‚Äî already in evaluation file.\")\n",
    "        continue\n",
    "\n",
    "    print(\"\\n============================================================\")\n",
    "    print(f\"Evaluating model: {run_name}\")\n",
    "    print(\"============================================================\")\n",
    "\n",
    "    try:\n",
    "        # Load model and tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(run_path)\n",
    "        model = AutoModelForMaskedLM.from_pretrained(run_path)\n",
    "        model.forward = safe_forward(model.forward)\n",
    "        model = model.to(device).eval()\n",
    "\n",
    "        # DataLoader\n",
    "        test_loader = DataLoader(full_dataset, batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=f\"Evaluating {run_name}\", leave=False):\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "                if loss is not None:\n",
    "                    total_loss += loss.item() * batch[\"input_ids\"].size(0)\n",
    "                    total_count += batch[\"input_ids\"].size(0)\n",
    "\n",
    "        if total_count > 0:\n",
    "            avg_loss = total_loss / total_count\n",
    "            perplexity = math.exp(avg_loss)\n",
    "            print(f\"‚úÖ {run_name} ‚Äî Loss: {avg_loss:.4f}, Perplexity: {perplexity:.2f}\")\n",
    "        else:\n",
    "            avg_loss, perplexity = None, None\n",
    "            print(f\"‚ö†Ô∏è {run_name} ‚Äî No valid batches.\")\n",
    "\n",
    "        new_results.append({\n",
    "            \"model_run\": run_name,\n",
    "            \"avg_loss\": avg_loss,\n",
    "            \"perplexity\": perplexity\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error evaluating {run_name}: {e}\")\n",
    "        new_results.append({\n",
    "            \"model_run\": run_name,\n",
    "            \"avg_loss\": None,\n",
    "            \"perplexity\": None\n",
    "        })\n",
    "\n",
    "# ============================================================\n",
    "# SAVE UPDATED RESULTS\n",
    "# ============================================================\n",
    "if new_results:\n",
    "    new_df = pd.DataFrame(new_results)\n",
    "    combined_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "    combined_df.to_csv(output_csv, index=False)\n",
    "    print(\"\\n============================================================\")\n",
    "    print(\"‚úÖ Evaluation Complete for New Runs\")\n",
    "    print(\"============================================================\")\n",
    "    print(new_df)\n",
    "else:\n",
    "    print(\"\\n‚úÖ No new 'run_next_' models found or all already evaluated.\")\n",
    "\n",
    "print(f\"\\nüìÅ Results saved to: {output_csv}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cae044",
   "metadata": {},
   "source": [
    "## Eval on val + text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ed9ada3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples in full dataset: 2,011\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_001_lr3e-05_wd0.01_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_001_lr3e-05_wd0.01_bs1_ga4_len512 ‚Äî Loss: 2.2554, Perplexity: 9.54\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_002_lr3e-05_wd0.01_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_002_lr3e-05_wd0.01_bs1_ga8_len512 ‚Äî Loss: 2.2208, Perplexity: 9.21\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_003_lr3e-05_wd0.01_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_003_lr3e-05_wd0.01_bs2_ga4_len512 ‚Äî Loss: 2.1862, Perplexity: 8.90\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_004_lr3e-05_wd0.01_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_004_lr3e-05_wd0.01_bs2_ga8_len512 ‚Äî Loss: 2.1850, Perplexity: 8.89\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_005_lr3e-05_wd0.05_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_005_lr3e-05_wd0.05_bs1_ga4_len512 ‚Äî Loss: 2.2533, Perplexity: 9.52\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_006_lr3e-05_wd0.05_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_006_lr3e-05_wd0.05_bs1_ga8_len512 ‚Äî Loss: 2.2839, Perplexity: 9.82\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_007_lr3e-05_wd0.05_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_007_lr3e-05_wd0.05_bs2_ga4_len512 ‚Äî Loss: 2.2136, Perplexity: 9.15\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_008_lr3e-05_wd0.05_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_008_lr3e-05_wd0.05_bs2_ga8_len512 ‚Äî Loss: 2.2111, Perplexity: 9.13\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_009_lr5e-05_wd0.01_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_009_lr5e-05_wd0.01_bs1_ga4_len512 ‚Äî Loss: 2.2117, Perplexity: 9.13\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_010_lr5e-05_wd0.01_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_010_lr5e-05_wd0.01_bs1_ga8_len512 ‚Äî Loss: 2.1810, Perplexity: 8.86\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_011_lr5e-05_wd0.01_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_011_lr5e-05_wd0.01_bs2_ga4_len512 ‚Äî Loss: 2.1399, Perplexity: 8.50\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_012_lr5e-05_wd0.01_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_012_lr5e-05_wd0.01_bs2_ga8_len512 ‚Äî Loss: 2.1479, Perplexity: 8.57\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_013_lr5e-05_wd0.05_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_013_lr5e-05_wd0.05_bs1_ga4_len512 ‚Äî Loss: 2.1355, Perplexity: 8.46\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_014_lr5e-05_wd0.05_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_014_lr5e-05_wd0.05_bs1_ga8_len512 ‚Äî Loss: 2.1631, Perplexity: 8.70\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_015_lr5e-05_wd0.05_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_015_lr5e-05_wd0.05_bs2_ga4_len512 ‚Äî Loss: 2.1864, Perplexity: 8.90\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_016_lr5e-05_wd0.05_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_016_lr5e-05_wd0.05_bs2_ga8_len512 ‚Äî Loss: 2.2654, Perplexity: 9.63\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_017_lr7e-05_wd0.01_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_017_lr7e-05_wd0.01_bs1_ga4_len512 ‚Äî Loss: 2.1526, Perplexity: 8.61\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_018_lr7e-05_wd0.01_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_018_lr7e-05_wd0.01_bs1_ga8_len512 ‚Äî Loss: 2.1420, Perplexity: 8.52\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_019_lr7e-05_wd0.01_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_019_lr7e-05_wd0.01_bs2_ga4_len512 ‚Äî Loss: 2.1679, Perplexity: 8.74\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_020_lr7e-05_wd0.01_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_020_lr7e-05_wd0.01_bs2_ga8_len512 ‚Äî Loss: 2.1710, Perplexity: 8.77\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_021_lr7e-05_wd0.05_bs1_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_021_lr7e-05_wd0.05_bs1_ga4_len512 ‚Äî Loss: 2.1292, Perplexity: 8.41\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_022_lr7e-05_wd0.05_bs1_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_022_lr7e-05_wd0.05_bs1_ga8_len512 ‚Äî Loss: 2.1377, Perplexity: 8.48\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_023_lr7e-05_wd0.05_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_023_lr7e-05_wd0.05_bs2_ga4_len512 ‚Äî Loss: 2.1224, Perplexity: 8.35\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_024_lr7e-05_wd0.05_bs2_ga8_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_024_lr7e-05_wd0.05_bs2_ga8_len512 ‚Äî Loss: 2.2357, Perplexity: 9.35\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_next_001_lr8e-05_wd0.05_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_next_001_lr8e-05_wd0.05_bs2_ga4_len512 ‚Äî Loss: 2.2050, Perplexity: 9.07\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_next_002_lr7e-05_wd0.03_bs2_ga4_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_next_002_lr7e-05_wd0.03_bs2_ga4_len512 ‚Äî Loss: 2.1658, Perplexity: 8.72\n",
      "\n",
      "============================================================\n",
      "Evaluating model: run_next_003_lr7e-05_wd0.05_bs4_ga2_len512\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ run_next_003_lr7e-05_wd0.05_bs4_ga2_len512 ‚Äî Loss: 2.1272, Perplexity: 8.39\n",
      "\n",
      "============================================================\n",
      "All Evaluations Complete ‚úÖ\n",
      "Results saved to: /home/mluser/AFML_RISHABH/Project/hyperparam_runs/evaluation_results_test_val.csv\n",
      "============================================================\n",
      "                                     model_run  avg_loss  perplexity\n",
      "0        run_001_lr3e-05_wd0.01_bs1_ga4_len512  2.255375    9.538872\n",
      "1        run_002_lr3e-05_wd0.01_bs1_ga8_len512  2.220805    9.214748\n",
      "2        run_003_lr3e-05_wd0.01_bs2_ga4_len512  2.186218    8.901483\n",
      "3        run_004_lr3e-05_wd0.01_bs2_ga8_len512  2.185007    8.890711\n",
      "4        run_005_lr3e-05_wd0.05_bs1_ga4_len512  2.253300    9.519099\n",
      "5        run_006_lr3e-05_wd0.05_bs1_ga8_len512  2.283941    9.815283\n",
      "6        run_007_lr3e-05_wd0.05_bs2_ga4_len512  2.213591    9.148512\n",
      "7        run_008_lr3e-05_wd0.05_bs2_ga8_len512  2.211147    9.126174\n",
      "8        run_009_lr5e-05_wd0.01_bs1_ga4_len512  2.211704    9.131262\n",
      "9        run_010_lr5e-05_wd0.01_bs1_ga8_len512  2.180987    8.855045\n",
      "10       run_011_lr5e-05_wd0.01_bs2_ga4_len512  2.139880    8.498418\n",
      "11       run_012_lr5e-05_wd0.01_bs2_ga8_len512  2.147922    8.567034\n",
      "12       run_013_lr5e-05_wd0.05_bs1_ga4_len512  2.135477    8.461079\n",
      "13       run_014_lr5e-05_wd0.05_bs1_ga8_len512  2.163084    8.697919\n",
      "14       run_015_lr5e-05_wd0.05_bs2_ga4_len512  2.186399    8.903092\n",
      "15       run_016_lr5e-05_wd0.05_bs2_ga8_len512  2.265390    9.634879\n",
      "16       run_017_lr7e-05_wd0.01_bs1_ga4_len512  2.152647    8.607616\n",
      "17       run_018_lr7e-05_wd0.01_bs1_ga8_len512  2.141963    8.516137\n",
      "18       run_019_lr7e-05_wd0.01_bs2_ga4_len512  2.167862    8.739582\n",
      "19       run_020_lr7e-05_wd0.01_bs2_ga8_len512  2.171032    8.767326\n",
      "20       run_021_lr7e-05_wd0.05_bs1_ga4_len512  2.129229    8.408379\n",
      "21       run_022_lr7e-05_wd0.05_bs1_ga8_len512  2.137697    8.479882\n",
      "22       run_023_lr7e-05_wd0.05_bs2_ga4_len512  2.122379    8.350983\n",
      "23       run_024_lr7e-05_wd0.05_bs2_ga8_len512  2.235725    9.353258\n",
      "24  run_next_001_lr8e-05_wd0.05_bs2_ga4_len512  2.205023    9.070458\n",
      "25  run_next_002_lr7e-05_wd0.03_bs2_ga4_len512  2.165837    8.721898\n",
      "26  run_next_003_lr7e-05_wd0.05_bs4_ga2_len512  2.127193    8.391282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# SETUP\n",
    "# ============================================================\n",
    "base_dir = \"/home/mluser/AFML_RISHABH/Project/hyperparam_runs\"\n",
    "results = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================================\n",
    "# PATCH FUNCTION\n",
    "# ============================================================\n",
    "def safe_forward(original_forward):\n",
    "    sig = inspect.signature(original_forward)\n",
    "    valid_keys = set(sig.parameters.keys())\n",
    "    def wrapped_forward(*args, **kwargs):\n",
    "        filtered = {k: v for k, v in kwargs.items() if k in valid_keys}\n",
    "        return original_forward(*args, **filtered)\n",
    "    return wrapped_forward\n",
    "\n",
    "# ============================================================\n",
    "# MERGE DATASETS (Assuming train_dataset, val_dataset, test_dataset exist)\n",
    "# ============================================================\n",
    "full_dataset = ConcatDataset([val_dataset, test_dataset])\n",
    "print(f\"Total samples in full dataset: {len(full_dataset):,}\")\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# LOOP OVER ALL RUNS\n",
    "# ============================================================\n",
    "for run_name in sorted(os.listdir(base_dir)):\n",
    "    run_path = os.path.join(base_dir, run_name)\n",
    "    if not os.path.isdir(run_path):\n",
    "        continue\n",
    "    print(\"\\n============================================================\")\n",
    "    print(f\"Evaluating model: {run_name}\")\n",
    "    print(\"============================================================\")\n",
    "\n",
    "    try:\n",
    "        # Load model and tokenizer\n",
    "        tokenizer = AutoTokenizer.from_pretrained(run_path)\n",
    "        model = AutoModelForMaskedLM.from_pretrained(run_path)\n",
    "        model.forward = safe_forward(model.forward)\n",
    "        model = model.to(device).eval()\n",
    "\n",
    "        # Set tokenizer in collator\n",
    "        data_collator.tokenizer = tokenizer\n",
    "\n",
    "        # DataLoader\n",
    "        test_loader = DataLoader(full_dataset, batch_size=8, collate_fn=data_collator)\n",
    "\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(test_loader, desc=f\"Evaluating {run_name}\", leave=False):\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                outputs = model(**batch)\n",
    "                loss = outputs.loss\n",
    "                if loss is not None:\n",
    "                    total_loss += loss.item() * batch[\"input_ids\"].size(0)\n",
    "                    total_count += batch[\"input_ids\"].size(0)\n",
    "\n",
    "        if total_count > 0:\n",
    "            avg_loss = total_loss / total_count\n",
    "            perplexity = math.exp(avg_loss)\n",
    "            print(f\"‚úÖ {run_name} ‚Äî Loss: {avg_loss:.4f}, Perplexity: {perplexity:.2f}\")\n",
    "        else:\n",
    "            avg_loss, perplexity = None, None\n",
    "            print(f\"‚ö†Ô∏è {run_name} ‚Äî No valid batches.\")\n",
    "\n",
    "        results.append({\n",
    "            \"model_run\": run_name,\n",
    "            \"avg_loss\": avg_loss,\n",
    "            \"perplexity\": perplexity\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error evaluating {run_name}: {e}\")\n",
    "        results.append({\n",
    "            \"model_run\": run_name,\n",
    "            \"avg_loss\": None,\n",
    "            \"perplexity\": None\n",
    "        })\n",
    "\n",
    "# ============================================================\n",
    "# SAVE RESULTS\n",
    "# ============================================================\n",
    "df = pd.DataFrame(results)\n",
    "output_csv = os.path.join(base_dir, \"evaluation_results_test_val.csv\")\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "print(\"\\n============================================================\")\n",
    "print(\"All Evaluations Complete ‚úÖ\")\n",
    "print(f\"Results saved to: {output_csv}\")\n",
    "print(\"============================================================\")\n",
    "print(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
